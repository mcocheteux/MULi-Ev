<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MULi-Ev: Maintaining Unperturbed LiDAR-Event Calibration</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">
  <link rel="stylesheet" href="style.css">
</head>

<body>
  <section class="bg-body-secondary">
    <div class="container text-center p-4">
      <h1>MULi-Ev: Maintaining Unperturbed LiDAR-Event Calibration</h1>
      <h3 class="text-secondary">CVPR 2024 (7th Workshop on Autonomous Driving)</h3>
      <hr>
      <p>
        <a href="https://www.cocheteux.eu">Mathieu Cocheteux</a>,
        <a href="https://www.hds.utc.fr/~moreajul">Julien Moreau</a>,
        <a href="https://www.hds.utc.fr/~fdavoine">Franck Davoine</a> <br>
        Université de technologie de Compiègne, CNRS<br>
        Heudiasyc Laboratory<br>
        France
      </p>
      <div class="all-links">
        <a href="https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Cocheteux_MULi-Ev_Maintaining_Unperturbed_LiDAR-Event_Calibration_CVPRW_2024_paper.html" target="_blank" rel="noopener noreferrer"
  class="btn btn-danger" role="button"><img src="./logos/document.svg" height="30" /
    class="my-1"><br>Proceedings</a>
        <a href="https://arxiv.org/pdf/2405.18021" target="_blank" rel="noopener noreferrer" class="btn btn-primary"
          role="button"><img src="./logos/document.svg" height="30" / class="my-1"><br>arXiv</a>
          <a href="https://cvpr2024.wad.vision/" target="_blank" rel="noopener noreferrer" class="btn btn-primary"
          role="button"><img src="./logos/link.svg" height="30" / class="my-1"><br>Workshop website</a>
      </div>
    </div>
  </section>
  <section>
    <div class="container p-4">
      <hr class="my-4">
      <h5>Abstract</h5>
      <p>
Despite the increasing interest in enhancing perception systems for autonomous vehicles the online calibration between event cameras and LiDAR--two sensors pivotal in capturing comprehensive environmental information--remains unexplored. We introduce MULi-Ev the first online deep learning-based framework tailored for the extrinsic calibration of event cameras with LiDAR. This advancement is instrumental for the seamless integration of LiDAR and event cameras enabling dynamic real-time calibration adjustments that are essential for maintaining optimal sensor alignment amidst varying operational conditions. Rigorously evaluated against the real-world scenarios presented in the DSEC dataset MULi-Ev not only achieves substantial improvements in calibration accuracy but also sets a new standard for integrating LiDAR with event cameras in mobile platforms. Our findings reveal the potential of MULi-Ev to bolster the safety reliability and overall performance of event-based perception systems in autonomous driving marking a significant step forward in their real-world deployment and effectiveness. 
      </p>
      <hr class="my-4">
      <h5>Citation</h5>
      <pre class="bg-body-secondary px-3 py-3"><code>@InProceedings{Cocheteux_2024_CVPR,
        author    = {Cocheteux, Mathieu and Moreau, Julien and Davoine, Franck},
        title     = {MULi-Ev: Maintaining Unperturbed LiDAR-Event Calibration},
        booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
        month     = {June},
        year      = {2024},
        pages     = {4579-4586}
    }
        </code></pre>
      <hr class="my-4">
    </div>
  </section>
</body>

</html>
